{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Spin Cycling of Partition Trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tree\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To illustrate this, consider the dyadic tree of $n$ levels on the interval $\\left[0,1\\right]$. This tree divides the interval into $2^n$ equally sized regions. Suppose we consider the distances between points in [0,1] in the tree metric. Points that lie within the same leaf folder have distance $\\frac{1}{2^n}$; points that lie within the same folder at the next higher level have twice that distance, and so on. Now if we consider $D_{tree}\\left(0,x\\right)$ in this metric, it behaves a natural manner:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = tree.dyadic_tree(6)\n",
      "y = np.array([t.tree_distance(0,x) for x in t.elements])\n",
      "plt.step(np.arange(0,t.size,1.0)/(1.0*t.size),y,'r')\n",
      "plt.ylim(0.0,1.2)\n",
      "plt.xlim(0.0,1.0)\n",
      "plt.title(\"$D_{tree}(0,x)$\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, now consider the point $\\frac{1}{2}-\\epsilon$. The distance function $D_{tree}\\left(\\frac{1}{2}-\\epsilon,x\\right)$ exhibits some strange behavior:\n",
      "\n",
      "Points to the left of this point have a somewhat normal progression of tree distances. However, points to the right of $\\frac{1}{2}$ all have distance 1 from $\\frac{1}{2}-\\epsilon$. This leads to the fact that $D_{tree}\\left(\\frac{1}{2}-\\epsilon,\\frac{1}{2}+\\epsilon\\right)=1$ even for small $\\epsilon$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = tree.dyadic_tree(6)\n",
      "y = np.array([t.tree_distance(31,x) for x in t.elements])\n",
      "plt.step(np.arange(0,t.size,1.0)/(1.0*t.size),y,'r')\n",
      "plt.ylim(0.0,1.2)\n",
      "plt.xlim(0.0,1.0)\n",
      "plt.title(\"$D_{tree}(0,x)$\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a significant defect in the tree structure, which arises from what might be termed the basic arbitrariness of dividing points into folders. When the underlying data in the \u201ctrue\u201d space is neatly separated into a tree-like structure, this problem is minimized because points which are close in the true space will be close in the tree metric under all circumstances. But when the underlying data forms a continuum or the trees are restricted to folders of a particular size, situations where two points which are close in truth are far apart in the tree metric occur often. In some sense, what this means is that we cannot trust our trees, no matter how well they are constructed.\n",
      "\n",
      "One good solution, suggested in (citation) and also by the method of random forests (citation) and elsewhere, is to construct many trees, implement some process using them, and then combine the results of the processes to make a final estimate. In the setting of the tree metric as above, we can see that the average distance over 256 trees appears relatively smooth and natural. The removal of the artifacts arising from the use of discrete trees in our process is an important part of the reconstruction process that follows. Note that we can also achieve \"better\" smoothness by creating random trees."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n= 8\n",
      "t = tree.dyadic_tree(n)\n",
      "distances = np.zeros(2**n)\n",
      "for i in xrange(2**n):\n",
      "    y = np.array([1.0 if i > x else t.tree_distance(i,x) for x in t.elements])\n",
      "    distances += y.take(np.arange(i,2**n+i,1),mode='wrap')/(2.0**n)\n",
      "plt.step(np.arange(0,t.size,1.0)/(1.0*t.size),distances,'r',label=\"All {} trees\".format(2**n))\n",
      "\n",
      "iters=20\n",
      "distances = np.zeros(2**n)\n",
      "for i in np.random.randint(0,2**n-1,iters):\n",
      "    y = np.array([1.0 if i > x else t.tree_distance(i,x) for x in t.elements])\n",
      "    distances += y.take(np.arange(i,2**n+i,1),mode='wrap')/(iters)\n",
      "plt.step(np.arange(0,t.size,1.0)/(1.0*t.size),distances,'g',label=\"{} random trees\".format(iters))\n",
      "\n",
      "y = np.array([t.tree_distance(0,x) for x in t.elements])\n",
      "plt.step(np.arange(0,t.size,1.0)/(1.0*t.size),y,'b',label=\"One tree\")\n",
      "\n",
      "plt.title(\"$D_{}(0,x)$\".format(\"{tree}\",iters))\n",
      "plt.ylim(0.0,1.4)\n",
      "plt.xlim(0.0,1.0)\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    }
   ],
   "metadata": {}
  }
 ]
}